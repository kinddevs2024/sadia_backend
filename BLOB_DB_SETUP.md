# Использование Vercel Blob для базы данных

Проект был обновлен для использования Vercel Blob Storage для хранения JSON файлов базы данных на production.

## Проблема

На Vercel файловая система доступна только для чтения, что вызывает ошибку:
```
EROFS: read-only file system, open '/var/task/data/collections/users.json'
```

Также при каждом изменении данных создавался новый файл в Blob Storage, что приводило к накоплению файлов.

## Решение

Используется Vercel Blob Storage для хранения JSON файлов базы данных. В development режиме используется файловая система.

**Важно:** Функция `writeCollectionBlob` теперь использует опцию `allowOverwrite: true`, что позволяет обновлять существующий файл вместо создания нового. Это предотвращает накопление дубликатов файлов в Blob Storage.

## Настройка

1. **Убедитесь, что пакет установлен:**
```bash
cd sadia_backend
npm install @vercel/blob
```

2. **На Vercel:**
   - Перейдите в настройки проекта на Vercel
   - Откройте вкладку "Storage"
   - Создайте новый Blob Store или используйте существующий
   - Переменная окружения `BLOB_READ_WRITE_TOKEN` будет установлена автоматически

3. **Для локальной разработки:**
   - Если переменная `BLOB_READ_WRITE_TOKEN` не установлена, будет использоваться файловая система
   - Если хотите тестировать Blob локально, добавьте в `.env.local`:
   ```
   BLOB_READ_WRITE_TOKEN=your_token_here
   ```

## Важно

⚠️ Все функции базы данных теперь имеют async версии. API routes уже async, поэтому они будут работать автоматически.

Функции с суффиксом `Async` (например, `getAllAsync`, `createAsync`) работают с Blob Storage.
Синхронные функции (например, `getAll`, `create`) работают только с файловой системой.

## Как это работает

1. **Запись данных:** При каждом обновлении коллекции функция `writeCollectionBlob` использует `allowOverwrite: true`, что обновляет существующий blob вместо создания нового. Это предотвращает накопление дубликатов файлов.

2. **Чтение данных:** Функция `readCollectionBlob` сначала проверяет кеш URL, затем ищет blob по имени. Если найдено несколько версий (старые данные), используется самая последняя версия.

3. **Кеширование:** URL blob кешируется для быстрого доступа. Кеш обновляется при каждой записи.

## Миграция данных

Данные нужно будет создать заново или мигрировать через API endpoints (создание пользователей, продуктов и т.д.).

Старые JSON файлы из `data/collections/` не будут автоматически мигрированы - их нужно будет загрузить через API или создать заново.

